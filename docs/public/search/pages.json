{"1":{"id":"1","title":"","subtitle":["Professional logging, metrics and analytics for your apps","JS Quickstart",".Net Core Quickstart","Targets / Sinks","How does it work?","JS Documentation",".Net Core Documentation","FAQs","Tutorials","License ","&"," Credits","Logary Prometheus for .Net Core","Logary Rutta","Pricing"],"description":"","body":"body{display:none} body{display:block} Professional logging, metrics and analytics for your apps Logary Analytics Logary is awesome for analytics and logging. Built with   for developers and business analysts.  Star Logary    Follow @logary Would you like to  proactively handle any negative experiences  that your users '  are having? Maybe you ' re 🤒/😴 giving all your interaction data to large american corporations ®? Or do you just want to measure  app latency  and  track revenue ? Then you ' ve come to the right place, because Logary solves that for you. Logary is a logging, tracing and metric library for .Net and JS as well as a stand-alone, ☁-native log router/ingress called Rutta. How does it work? .Net package   JS package Learn how to add analytics to your web/react-native apps. Instrument your backend services for a cloud native architecture. Logary can send logs, metrics and spans to a wide range of targets. Have a look here to see what ' s available! Let ' s have a look at this site and how we do analytics here... Read up on how to use the JavaScript library Read up on how to use the library Layout for FAQ page. Lorem ipsum dolor sit amet, consectetuer adipiscing elit Learn how to use Logary to visualise the state and interactions with your apps. Layout for license  &  credits page. Consectetuer adipiscing elit. xmlSpace= \" preserve \" > With  Logary.Prometheus  you can expose you app metrics for Prometheus and Grafana. A stand-alone, cloud-native log router and ingestion point for HTTP, UDP, ZeroMQ, TCP, and more. Purchase a commercial license to super-charge your company ' s logging, metrics and analytics, and improve Logary! Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/"},"2":{"id":"2","title":" — Logary","subtitle":["An example","Passing values around","Fields","Gauges","Tags","SinkTargetNames","SinkTargetNames","Filtering logs","Log levels","Logging from modules","Logging from classes","Structured logging and interpolation","Per-process event processing","Metrics ","&"," EventProcessing pipeline"],"description":"","body":"body{display:none} body{display:block} .Net Core Documentation Logary Analytics Start .Net Core Documentation   Reading time:  12  minutes Suppose you ' re measuring values coming from a car. This is what that could look like: module  Bicycle.SupervisorProcess\n open  Logary\n open  Logary.Message\n\n //  \" the sensor \" \n let  logger = Log.create  \" Car.SupervisorProcess \" \n\n let  tyreTick () =\n   //  \" the event is triggered, e.g. via a polling supervisor \" \n  logger.info (\n    eventX  \" Tyres \" \n     > >  addGauge  \" front \"  (Gauge (Float  79.2421 , Units.Pascal)))\n     > >  addGauge  \" back \"  (Gauge (Float  90.159 , Units.Pascal))) Context is generally classified into these categories: (you can try these code on test.fsx in Logary.Tests) prefix with  \" _fields. \" Fields are the structured data when you use structure logging like (https://messagetemplates.org/), there are mainly two style to achieve this. open  Logary\n open  Logary.Message\n\n type   SomeInfo () =\n   member  x.PropA =\n     45 \n   member  x.PropB =\n    raise (Exception ( \" Oh noes, no referential transparency here \" ))\n with \n   interface  IFormattable  with \n     member  x.ToString (format, provider) =  \" PropA is 45 and PropB raise exn \" \n\n let  oneObj = SomeInfo ()\n\neventFormat (Info,  \" Hey {userName}, here is a default {info} and stringify {$info} and destructure {@info} \" ,  \" You \" , oneObj)\n  | >  setSimpleName  \" Company.APIModule.calculateTotals \" \n  | >  MessageWriter.levelDatetimeMessagePath.format\n\n // alternative style: \n\nevent Info  \" user write some info \" \n  | >  setField  \" userName \"   \" You \" \n  | >  setField  \" data \"  oneObj\n  | >  setSimpleName  \" Company.APIModule.calculateTotals \" \n  | >  MessageWriter.levelDatetimeMessagePath.format Results in: val it : string =\n   \" I 2018-01-26T09:08:21.6590074+00:00: Hey  \" You \" , here is a default  \" PropA is 45 and PropB raise exn \"  and stringify  \" FSI_0002+SomeInfo \"  and destructure SomeInfo { PropB:  \" The property (PropB) accessor threw an (TargetInvocationException): Oh noes, no referential transparency here \" , PropA: 45 } [Company.APIModule.calculateTotals]\n  fields:\n    info = > \n      SomeInfo {\n        PropB = >   \" The property (PropB) accessor threw an (TargetInvocationException): Oh noes, no referential transparency here \" \n        PropA = >  45}\n    userName = >   \" You \" \" prefix with  \" _logary.gauge. \" which value is Gauge(float, units). An instantaneous value. Imagine the needle showing the speed your car is going or a digital display showing the same instantaneous metric value of your car ' s speed. you can add gauges with one message, or use gauge as the message. The difference between them is, if you use gauges as the message, the value in message are auto generate by gauges when formatting them : type   User   =\n  {\n    id      : int\n    name    : string\n    created : DateTime\n  }\n\n let  date20171111 =  DateTime.Parse( \" 2017-11-11 \" )\n let  foo () = { id =  999 ; name =  \" whatever \" ; created = date20171111}\n\n\n let  ex = exn  \" exception with data in it \" \nex.Data.Add ( \" data 1 in exn \" ,  1 )\nex.Data.Add ( \" data foo in exn \" , foo ())\nex.Data.Add (foo(), foo())\n\nMessage.event Error  \" ouch \" \n| >  Message.addExn ex\n| >  Message.addExn (exn  \" another exception \" )\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePathNewLine.format\n\n val  it : string =\n   \" E 2018-01-26T09:30:37.7648557+00:00: ouch [somewhere.this.message.happened]\n  others:\n    _logary.errors = > \n      -\n        System.Exception {\n          Message = >   \" another  exception \" \n          HResult = >  -2146233088}\n      -\n        System.Exception {\n          Message = >   \" exception   with  data  in  it \" \n          Data = > \n             \" data  1   in  exn \"  = >  1\n             \" data foo  in  exn \"  = > \n              User {\n                name = >   \" whatever \" \n                id = >  999\n                created = >  11/11/2017 12:00:00 AM}\n            - key = > \n                User {\n                  name = >   \" whatever \" \n                  id = >  999\n                  created = >  11/11/2017 12:00:00 AM}\n              value = > \n                User {\n                  name = >   \" whatever \" \n                  id = >  999\n                  created = >  11/11/2017 12:00:00 AM}\n          HResult = >  -2146233088}\n \" prefix with  \" _logary.tags \" which value is a set , tags are help with identity one type message when you do some pipeline processing. > \n-  let  pipeLine =\n-    Events.events\n-    | >  Events.tag  \" queue \" \n-    | >  Pipe.map ( fun  msg - >  {msg  with  value =  \" https://github.com/alexandrnikitin/MPMCQueue.NET \" })\n-\n-\n-\n-  let  logm =\n-   Config.create  \" svc \"   \" localhost \" \n-   | >  Config.target (Targets.Console.create Targets.Console.empty  \" my console target \" )\n-   | >  Config.processing pipeLine\n-   | >  Config.build\n-   | >  run\n-\n-  let  lg = logm.getLogger (PointName.parse  \" give.some.example.here \" )\n-\n- Message.event Info  \" MPMCQueue \" \n- | >  Message.tag  \" queue \" \n- | >  Message.tag  \" high-performance \" \n- | >  Message.tag  \" lock-free \" \n- | >  Message.tag  \" multiple-consumers \" \n- | >  lg.logSimple\n-\n- ;;\nI  2018 -01 -26 T09: 51 : 06.0523375 + 00 : 00 : https: //github.com/alexandrnikitin/MPMCQueue.NET [give.some.example.here] \n  others:\n    _logary.host = >   \" localhost \" \n    _logary.service = >   \" svc \" \n    _logary.tags = >  [ \" high-performance \" ,  \" lock-free \" ,  \" multiple-consumers \" ,  \" queue \" ] prefix with  \" _logary.sink.targets \" They are generally are set by Events Processing, you can define which targets (sinks) your message will go. if not set, message will go to all targets and let the targets themself to decide whether or not to accept it. let  pipeLine =\n   Events.events\n   | >  Events.tag  \" queue \" \n   | >  Pipe.map ( fun  msg - >  {msg  with  value =  \" https://github.com/alexandrnikitin/MPMCQueue.NET \" })\n   | >  Events.sink [ \" nice console \" ]\n\n let  logm =\n  Config.create  \" svc \"   \" localhost \" \n  | >  Config.target (Targets.Console.create Targets.Console.empty  \" my console target \" )\n  | >  Config.target (Targets.LiterateConsole.create Targets.LiterateConsole.empty  \" nice console \" )\n  | >  Config.processing pipeLine\n  | >  Config.build\n  | >  run\n\n let  lg = logm.getLogger (PointName.parse  \" give.some.example.here \" )\n\nMessage.event Info  \" MPMCQueue \" \n| >  Message.tag  \" queue \" \n| >  Message.tag  \" high-performance \" \n| >  Message.tag  \" lock-free \" \n| >  Message.tag  \" multiple-consumers \" \n| >  lg.logSimple this will only show on LiterateConsole, not normal Console. things you don ' t want to show on the message value, but show on the backstore. e.g: some structured data not belong the message template or data you can use in the EventProcessing Pipeline. Message.eventFormat (Info,  \" {userId} create an shopping list at {createdTime} \" ,  \" 9999 \" , DateTime.Now )\n| >  Message.setContext  \" user name \"   \" :) \" \n| >  Message.setContext  \" shopping list \"  [ \" cat \" ; \" cat food \" ; \" books \" ; \" drinks \" ]\n| >  Message.setSimpleName  \" somewhere.this.message.happened \" \n| >  MessageWriter.levelDatetimeMessagePath.format\n\n val  it : string =\n   \" I 2018-01-26T10:11:54.5221326+00:00:  \" 9999 \"  create an shopping list at 1/26/2018 6:11:54 PM [somewhere.this.message.happened]\n  fields:\n    userId = >   \" 9999 \" \n    createdTime = >  1/26/2018 6:11:54 PM\n  others:\n    user name = >   \" :) \" \n    shopping list = >  [ \" cat \" ,  \" cat food \" ,  \" books \" ,  \" drinks \" ] \" A logger have a minimum level which message ' s level below it is not processed when logging these message. Can give us Low overhead logging – evaluate your Message only if a level is switched on. Especially when you use logging api with message factory. A logger ' s minimum level are config through Config.loggerMinLevel  \" a.b.* \"  LogLevel.Fatal on logary conf (usually globally) use a specific name or some hierarchy path. And can be switch on fly logm.switchLoggerLevel ( \" a.b.* \" , LogLevel.Info),this will only affect the loggers (its name, not its instance) which have been created beafore. e.g. the default level is Error on prod, use a pipe line detect an error message, switch to Info for 5 mins then change it back. can be use for auto collecting more useful info when things goes wrong. let  someRuleOnTarget =\n  Rule.empty\n  | >  Rule.setMinLevel LogLevel.Error  // this target will only get message about error level (inclusive) \n  | >  Rule.setPath (System.Text.RegularExpressions.Regex( \" a.b.c.* \" ))  // only accept message name under a.b.cxxxxx \n  | >  Rule.setAcceptIf ( fun  msg - >  msg | >  Message.hasTag  \" emergency \" )\n\n let  tconf =\n  Targets.LiterateConsole.create Targets.LiterateConsole.empty  \" nice console \" \n  | >  TargetConf.addRule someRuleOnTarget\n let  logm =\n  Config.create  \" svc \"   \" localhost \" \n  | >  Config.target tconf\n  | >  Config.loggerMinLevel  \" a.b.* \"  LogLevel.Fatal   // logger under a.bxxxx path only process Fatal message \n  | >  Config.loggerMinLevel  \" a.b.c.* \"  LogLevel.Info  // logger under a.b.cxxxx path can process message above Info \n  | >  Config.build\n  | >  run\n\n let  abc = logm.getLogger (PointName.parse  \" a.b.cxxx \" )\n let  ab = logm.getLogger (PointName.parse  \" a.bxxx \" )\n\nabc.verbose (Message.eventX  \" abc.Info \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // no invoke \nabc.error (Message.eventX  \" abc.Error \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // invoke, but will not go to target \nabc.error (Message.eventX  \" abc.Error with emergency tag \"   > >  ( fun  msg - >  printfn  \" invoke%s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n\nab.error (Message.eventX  \" ab.Error \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // no invoke \nab.fatal (Message.eventX  \" ab.Fatal \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n\n >  abc.verbose (Message.eventX  \" abc.Info \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // no invoke \n- ;;\n val  it : unit = ()\n\n >  abc.error (Message.eventX  \" abc.Error \"   > >   fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  // invoke, but will not go to target \n- ;;\ninvoke abc.Error\n val  it : unit = ()\n\n >  abc.error (Message.eventX  \" abc.Error with emergency tag \"   > >  ( fun  msg - >  printfn  \" invoke%s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n- ;;\ninvokeabc.Error  with  emergency tag\n val  it : unit = ()\n\n >  [ 19 : 06 : 33  ERR] abc.Error  with  emergency tag  < a.b.cxxx > \n  others:\n    _logary.host = >   \" localhost \" \n    _logary.service = >   \" svc \" \n    _logary.tags = >  [ \" emergency \" ]\n\n >  ab.error (Message.eventX  \" ab.Error \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // no invoke \n- ;;\n val  it : unit = ()\n\n >  ab.fatal (Message.eventX  \" ab.Fatal \"   > >  ( fun  msg - >  printfn  \" invoke %s \"  msg.value; msg)  > >  Message.tag  \" emergency \" )  // hurray \n- ;;\ninvoke ab.Fatal\n[val19: 07 : 45   FTLit]  ab.Fatal:  unit < a.bxxx > \n  others:\n    _logary.host = >   \" localhost \" \n    =_logary.service = >   \" svc \" \n    _logary.tags  = >  [ \" emergency \" ] The highest log level is Fatal, which should be reserved for things that make your service/process crash. Things like;  \" my disk is full and I ' m a database trying to start \" , or  \" I ' m a 2-tier service built with a database, that I cannot do any work without \"  warrant the Fatal level. The next level is Error, which should be reserved for what you consider to be edge-cases. E.g. if the data received from a socket is corrupt, or there was an unhandled exception that you as a programmer did not have in your mental model while writing the code. These events should be logged at the Error level. At this level human beings are normally directly alerted. Warn is for things like 100 failed password attempts within 5 minutes, for one of your users, or a temporary network glitch while communicating with a  \" resource \"  such as your database. If these events for an anomaly persist over time, humans may be alerted. At Info level, I like to put events and gauges that measure company-relevant stuff, like when users sign in, sign up, an integration has to perform a retry or a service was started/restarted. Debug level is the default level and the work-horse. You normally log all metrics at this level. Verbose is the level when you want that little extra. Not normally enabled. Let ' s say you have a module in your F# code that you want to log from. You can either get a logger like shown in Hello World, or you can do something like this: module  MyCompany.Sub.MyModule\n\n open  Logary\n\n let  logger = Logging.getCurrentLogger ()\n\n let  logInUser () =\n   // do something \n  Message.event Info  \" User logged in \"  | >  Logger.logSimple logger\n   // do more stuff If you want to name your logger with a specific name, you can use Logging.getLoggerByName instead. (This is different for the Facade file) Similarly, sometimes you want to log from a class, and perhaps log some metrics too. namespace  MyCompany.Sub\n\n open  Logary\n\n type   Worker () =\n   let  logger =\n    Logging.getLoggerByName  \" MyCompany.Sub.Worker \" \n\n   let  workName =\n    PointName [|  \" MyCompany \" ;  \" Sub \" ;  \" Worker \" ;  \" workDone \"  |]\n\n   let  getAnswers (amount : float) =\n     // work work work \n     42  * amount\n\n   member  x.Work (amount : float) =\n     // Initially, log how much work is to be done \n     // the only  \" supported \"  metric is a gauge (a value at an instant) \n    Message.gauge workName amount | >  Logger.logSimple logger\n\n     // do some work, logging how long it takes: \n     let  everything = Logger.time logger ( fun  () - >  getAnswers amount)\n\n     // return result \n    everything In this example you learnt how to send arbitrary metrics to Logary (the gauge) and also how to time how long certain method calls take in your system. Make it a habit to log these sort of gauges all over your code base while you write your code, to make it much easier to understand the system as it develops. In fact, the more you do this, the more use you will have of Logary and of the dashboard you put up in Kibana (via Logstash) or Grafana (via InfluxDb). Put it up on a big TV in your office and you ' ll develop a second sense of whether the system is doing well or not, just from looking at the graphs. The templates syntax can be found here:  Message Templates are a superset of standard .NET format strings, so any format string acceptable to string.Format() will also be correctly processed by logary. Property names are written between and braces Formats that use numeric property names, like 0 and 1 exclusively, will be matched with the Format method ' s parameters by treating the property names as indexes; this is identical to string.Format() ' s behaviour  If any of the property names are non-numeric, then all property names will be matched from left-to-right with the Format method ' s parameters Property names may be prefixed with an optional operator, @ or $, to control how the property is serialised Property names may be suffixed with an optional format, e.g. :000, to control how the property is rendered; these format strings behave exactly as their counterparts within the string.Format() syntax Sometimes you need a metric that runs continuously over time. A Ticker can be seems as a metric, it can be auto triggered or by manually. A ticker can be chained in an pipe line (EventProcessing). We have some windows performance counter metrics that you can use. But you sometimes want to chain metrics from events or gauges happening inside your own application. We have some windows performance counter metrics that you can use. module  Program\n\n open  System\n open  System.Threading\n open  Hopac\n open  Logary\n open  Logary.Configuration\n open  NodaTime\n open  Logary.Targets\n open  Logary.Metrics.WinPerfCounters\n open  Logary.EventProcessing\n\n module  Sample =\n\n   let  randomWalk pn =\n     let  reducer state =  function \n      | _ - > \n        state\n\n     let  ticker (rnd : Random, prevValue) =\n       let  value =\n         let  v = (rnd.NextDouble() -  0.5 ) *  0.3 \n         if  abs v  <   0.03   then  rnd.NextDouble() -  0.5 \n         elif  v + prevValue  <   -1.  || v + prevValue  >   1.   then  -v + prevValue\n         else  v + prevValue\n\n       let  msg = Message.gauge pn value\n\n      (rnd, value), msg\n\n     let  state =\n       let  rnd = Random()\n      rnd, rnd.NextDouble()\n\n    Ticker.create state reducer ticker\n\n [ < EntryPoint > ] \n let  main argv =\n   let   inline  ms v = Duration.FromMilliseconds (int64 v)\n   let  pn name = PointName [|  \" Logary \" ;  \" Samples \" ; name |]\n   use  mre =  new  ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n   let  clock = SystemClock.Instance\n   let  tenSecondsEWMATicker = EWMATicker (Duration.FromSeconds  1 L, Duration.FromSeconds  10 L, clock)\n   let  randomWalk = Sample.randomWalk  \" randomWalk \" \n   let  walkPipe =  Events.events | >  Pipe.tickTimer randomWalk (TimeSpan.FromMilliseconds  500. )\n   let  systemMetrics = Events.events | >  Pipe.tickTimer (systemMetrics (PointName.parse  \" sys \" )) (TimeSpan.FromSeconds  10. )\n   let  processing =\n    Events.compose [\n       walkPipe\n       | >  Events.sink [ \" WalkFile \" ;]\n\n       walkPipe\n       | >  Pipe.choose (Message.tryGetGauge  \" randomWalk \" )\n       | >  Pipe.counter ( fun  _ - >   1 L) (TimeSpan.FromSeconds  2. )\n       | >  Pipe.map ( fun  counted - >  Message.eventFormat (Info,  \" There are {totalNumbers} randomWalk within 2s \" , [|counted|]))\n       | >  Events.sink [ \" Console \" ;]\n\n       walkPipe\n       | >  Pipe.choose (Message.tryGetGauge  \" randomWalk \" )\n       | >  Pipe.map ( fun  _ - >   1 L)  // think of randomWalk as an event, mapping to 1 \n       | >  Pipe.tickTimer tenSecondsEWMATicker (TimeSpan.FromSeconds  5. )\n       | >  Pipe.map ( fun  rate - >  Message.eventFormat (Info,  \" tenSecondsEWMA of randomWalk ' s rate is {rateInSec} \" , [|rate|]))\n       | >  Events.sink [ \" Console \" ;]\n\n       systemMetrics\n       | >  Pipe.map Array.toSeq\n       | >  Events.flattenToProcessing\n       | >  Events.sink [ \" LiterateConsole \" ;  \" WPCMetricFile \" ;]\n    ]\n\n   let  console = Console.create Console.empty  \" Console \" \n   let  literalConsole = LiterateConsole.create LiterateConsole.empty  \" LiterateConsole \" \n   let  randomWalkFileName = File.Naming ( \" {service}-RandomWalk-{date} \" ,  \" log \" )\n   let  wpcFileName = File.Naming ( \" {service}-wpc-{date} \" ,  \" log \" )\n   let  randomWalkTarget = File.create (File.FileConf.create Environment.CurrentDirectory randomWalkFileName)  \" WalkFile \" \n   let  wpcFileTarget = File.create (File.FileConf.create Environment.CurrentDirectory wpcFileName)  \" WPCMetricFile \" \n   let  logary =\n    Config.create  \" Logary.Examples.MetricsWriter \"   \" localhost \" \n    | >  Config.targets [console; literalConsole; randomWalkTarget; wpcFileTarget;]\n    | >  Config.ilogger (ILogger.Console Verbose)\n    | >  Config.processing processing\n    | >  Config.build\n    | >  run\n\n  mre.Wait()\n   0 By wrapping it up like this, you can drastically reduce the amount of code a given service sends by pre-computing much of it. It ' s also a good sample of reservoir usage; a fancy name of saying that it ' s an algorithm that works on more than one gauge at a time, to produce a derived metric. An example Passing values around Filtering logs Log levels Logging from modules Logging from classes Structured logging and interpolation Per-process event processing Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/docs\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/dotnet/docs"},"3":{"id":"3","title":" — Logary","subtitle":["Prometheus"],"description":"","body":"body{display:none} body{display:block} Prometheus Logary Analytics Start Prometheus xmlSpace= \" preserve \" >   Reading time:  2  minutes Logary supports Prometheus. Reference  Logary.Prometheus  and create metrics: TBD module  A =\n   open  Logary.Metric\n\n   let  logger = Log.create  \" xxx.yyy \" \n\n   let  parseConfigFailedCounter =\n    GaugeConf.create {name= \" xxx_yyy_parse_config_faild_total \" ; description=  \" the total number for xxx.yyy.parseConfig faild \" ; labelNames = [|  \" path \"  |]}\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n\n   // add gauge metric and histogram with buckets [| 0.001; 0.005; 0.01; 0.025; 0.05; 0.1; 1.0|] in the same time \n   let  parseConfigGaugeWithHistogram =\n    GaugeConf.create {name= \" xxx_yyy_parse_config_latency_seconds \" ; description=  \" xxx.yyy.parseConfig latency in seconds \" ; labelNames = [||]}\n    | >  GaugeConf.withHistogram [|  0.001 ;  0.005 ;  0.01 ;  0.025 ;  0.05 ;  0.1 ;  1.0 |]\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n    | >  Metric.noLabels\n\n\n   // using default buckets:  [| 0.005; 0.01; 0.025; 0.05; 0.075; 0.1; 0.25; 0.5; 0.75; 1.; 2.5; 5.0; 7.5; 10. |] \n   let  parseConfigLatencyHistogram =\n    HistogramConf.create( \" xxx_yyy_parse_config_latency_seconds \" ,  \" xxx.yyy.parseConfig latency in seconds \" )\n    | >  LogManager.DefaultMetricRegistry.registerMetric\n    | >  Metric.noLabels\n\n   // using hookup and shortcut style \n   let  parseConfigWithShortcut path =\n     try \n       // if we hook up metric at logary ' s conf, then there is no need to do other things here. \n       // span will be treated as gauges when span has been finished. \n       use  traceSpan =\n        logger.buildSpan()\n        | >  Span.setMessage (eventX  \" time usage about parse config with {path} \"   > >  setField  \" path \"  path)\n        | >  Span.start\n\n       // do some work here \n      failwith  \" not implement \" \n      \n     with  ex - > \n      eventX  \" parse config from {path} failed \" \n       > >  setField  \" path \"  path\n       > >  enableCounterMetric {name= \" xxx_yyy_parse_config_faild_total \" ; description=  \" the total number for xxx.yyy.parseConfig faild \" ; labelNames = [|  \" path \"  |]}\n      | >  logger.error\n\n   // using metric as a separate instance style \n   let  parseConfig path =\n     try \n       let  traceSpan =\n        logger.buildSpan()\n        | >  Span.setMessage (eventX  \" time usage about parse config with {path} \"   > >  setField  \" path \"  path)\n        | >  Span.start\n\n       // do some work here \n      failwith  \" not implement \" \n\n\n       let  spanLog = traceSpan.finish id\n       // gauge with histogram like below \n      parseConfigGaugeWithHistogram.set (Duration.FromTicks(spanLog.duration).TotalSeconds)\n       // or metric only histogram like below \n      parseConfigLatencyHistogram.observe (Duration.FromTicks(spanLog.duration).TotalSeconds)\n\n     with  ex - > \n      eventX  \" parse config from {path} failed \" \n       > >  setField  \" path \"  path\n      | >  logger.error\n\n      (parseConfigFailedCounter.labels [| path |]).inc  1. Prometheus Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/prometheus\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/dotnet/prometheus"},"4":{"id":"4","title":" — Logary","subtitle":["Getting started","Hello world (F#)","Hello world (C#)"],"description":"","body":"body{display:none} body{display:block} .Net Quickstart Logary Analytics Start .Net Quickstart   Reading time:  5  minutes After installing the .NET Core SDK, open a command prompt. Type the following dotnet commands to create and run a C# application. $ dotnet new console -lang F# $ dotnet add package Logary $ dotnet run module  Logary.ConsoleApp.Program\n\n open  System\n open  Hopac\n open  Logary\n open  Logary.Message\n open  Logary.Configuration\n open  Logary.Targets\n\n [ < EntryPoint > ] \n let  main argv =\n   use  mre =  new  System.Threading.ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n\n   let  logary =\n    Config.create  \" Logary.ConsoleApp \"   \" laptop \" \n    | >  Config.target (LiterateConsole.create LiterateConsole.empty  \" console \" )\n    | >  Config.ilogger (ILogger.Console Debug)\n    | >  Config.build\n    | >  run\n\n   let  logger = logary.getLogger  \" Logary.HelloWorld \" \n\n  logger.info (eventX  \" Hello world \" )\n\n  mre.Wait()\n   0 ﻿ namespace   Logary.CSharpExample \n{\n     using  System;\n     using  System.Threading;\n     using  System.Threading.Tasks;\n     using  Configuration;\n     using  CSharp;\n     using  Targets;\n     using  Adapters.Facade;\n\n     public   static   class   Program \n    {\n         public   static  Task < LogManager >   StartLiterate ( ) \n        {\n             return  LogaryFactory.New( \" Logary.CSharpExample \" , \" laptop \" ,\n                with = >  with.InternalLogger(ILogger.NewConsole(LogLevel.Debug))\n                        .Target < LiterateConsole.Builder > ( \" console1 \" ));\n        }\n\n         public   static   async  Task  SampleUsage ( Logger logger ) \n        {\n             // without async \n            logger.LogSimple(MessageModule.Event(LogLevel.Info,  \" User logged in \" ));\n            \n             // await placing the Hello World event in the buffer \n             await  logger.LogEvent(LogLevel.Debug,  \" Hello world. Important? {important} \" ,  new \n            {\n                important =  \" yes \" \n            });\n\n             // await logging the fatal event and getting an ack back from each of the configured \n             // targets \n             await  logger.LogEvent(LogLevel.Fatal,  \" Fatal application error on finaliser thread. \" , waitForAck:  true );\n\n             await  logger.LogEvent(LogLevel.Verbose,  \" We need to log this with backpressure. \" ,  new \n            {\n                tags =  new [] {  \" tag1 \" ,  \" tag2 \"  }\n            });\n\n             // alternatively, you can use the ack-explicit functions together with the \n             // data object model that ' s MessageModule. \n             var  message = MessageModule.Event(LogLevel.Warn,  \" Here be dragons! \" );\n             await  logger.LogWithAck(message);\n\n             var  val = logger.Time(() = > \n                    {\n                         for  ( int  i =  0 ; i  <   100 ; i++)\n                            Thread.Sleep( 1 );\n\n                         return   32 ;\n                    },  \" sample.config.computeAnswerToEverything \" )\n                ();\n\n             await  logger.LogEventFormat(LogLevel.Warn,\n                 \" {horses} is the answer to the universe and everything \" ,\n                val);\n\n             await  logger.Time(\n                    () = >  logger.LogEvent(LogLevel.Debug,  \" I wonder how long this takes \" ))\n                ();\n\n             try \n            {\n                 throw   new  ApplicationException( \" thing went haywire \" );\n            }\n             catch  (Exception e)\n            {\n                 await  logger.LogEventFormat(LogLevel.Fatal,  \" Unhandled {exception}! \" , e);\n            }\n        }\n\n         public   static   void   SampleCibryyUsage ( Cibryy.Logging.ILogger logger ) \n        {\n           Cibryy.Core.Work(logger);\n           Cibryy.Core.WorkBackpressure(logger);\n           Cibryy.Core.ErrorWithBP(logger);\n           Cibryy.Core.SimpleWork(logger);\n           Cibryy.Core.GenerateAndLogExn(logger);\n           Cibryy.Core.StaticWork();\n        }\n\n         public   static   int   Main ( string [] args ) \n        {\n             // normal console app boilerplate; \n             var  mre =  new  ManualResetEventSlim( false );\n            System.Console.CancelKeyPress += (sender, arg) = >  mre.Set();\n\n             var  logary = StartLiterate().Result;\n            \n             // Usage with a library: \n            LogaryFacadeAdapter.Initialise < Cibryy.Logging.ILogger > (logary);\n             var  logger = logary.GetLogger( \" main \" );\n            SampleCibryyUsage(LoggerCSharpAdapter.Create < Cibryy.Logging.ILogger > (logger));\n            \n             // Usage in this program: \n            SampleUsage(logger).Wait();\n                \n             // Wait for CTRL+C \n            mre.Wait();\n             return   0 ;\n        }\n    }\n}\n Getting started Hello world (F#) Hello world (C#) Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/quickstart\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/dotnet/quickstart"},"5":{"id":"5","title":" — Logary","subtitle":["InfluxDB","File target","Configuration","Policies ","&"," specifications","Performance","Handling of errors","Invariants","Overview of buffers","Notes on FILE_FLAG_NO_BUFFERING","Work to be done","Stackdriver target","Configuration","Further work","Jaeger tracing target","Install jaeger tracing","Usage","What does it look like?","AliYun Log Service target","Usage","What does it look like?","Azure AppInsights target","Commercial targets","Mixpanel","OpsGenie","elmah.io","SumoLogic (community-contributed)","Want your SaaS-logging service as a Target?"],"description":"","body":"body{display:none} body{display:block} Targets / Sinks Logary Analytics Start Targets / Sinks   Reading time:  11  minutes Suppose you ' re measuring values coming from a car. This is what that could look like: Events will be logged to InfluxDb like such:   \" pointName, event=template, ctx1=ctxval1, ctx2=ctxval2 field1=fieldval1, field2=fieldval2 value=1i 14566666xxxx \" In other words, fields will be influx values and context fields will be influx tags. The timestamp of the Message will be at the end as the timestamp of the sent line Events will be logged in these influx measure names, so that you could e.g. put    \" event_fatal \"   as an annotation in Grafana:  event_verbose   event_debug   event_info  event_warn   event_error   event_fatal  Logary ' s file target is primarily geared towards systems that are running on single machines as it prints a human-readable format, rather than a machine- readable one. The default configuration of the file target rotates log files greater than 200 MiB and deletes log files when the configured folder size is larger than 3 GiB. Folders that don ' t exist when the target starts are automatically created on target start-up in the current service ' s security context. Should the calls to create the folder fail, the target is never started, but will restart continuously like any ther Logary target. let  fileConf =\n  { File.FileConf.create logDir (Naming ( \" {service}-{host}-{datetime} \" ,  \" log \" )) }\n\n // ... withTargets [ \n  File.create fileConf  \" file \" \n // ] ... Or in C#: // set  ' logDir '  to specific path like Environment.CurrentDirectory if you are on windows \n.Target < File.Builder > (\n     \" file \" ,\n    file = >  file.Target.FileSystem( new  FileSystem.DotNetFileSystem(logDir))\n                       .Naming( \" {service}-{host}-{datetime} \" ,  \" log \" ).Done()) You can specify a number of deletion and rotation policies when configuring the file target. The deletion policies dictate when the oldest logs should be deleted, whilst the rotation policies dictates when the files should be rotated (thereby the previous file archived). Furthermore, you can specify a naming specification that dictates how the files should be named on disk. Deletion of files happen directly when at least one deletion policy has triggered. Rotation of files happen directly when at least one rotation policy has triggered. Naming specifications should automatically be amended with sequence number, should that be required. The   File   target is a performance-optimised target. Logging always happens on a separate thread from the caller, so we try to reach a balance between throughput and latency on ACKs. On Windows, overlapped IO is not used, because the files are opened in Append mode, should have equivalent performance. This means we should have similar performance on Linux and Windows. The formatters used for the  File  target should be writing to  TextWriter  instances to avoid creating extra string copies in memory. The file target is thought as a last-chance target, because by default, logs should be shipped from your nodes/machines to a central logging service. It can also be nicely put to use for local console apps that need to log to disk. Non-target-fatal  IOExceptions , for example when NTFS ACKs file deletes but still keeps the file listable and available for some duration afterwards are retried on a case-by-case basis. Internal Warn-level messages are logged. Fatal  IOExceptions  – more other cases; directory not found, file not found, etc. are not retried. The target should crash and restart. Its current batch is then retried forever, while logging internal Fatal-level exceptions. The File target is modelled as a transaction log and trades speed against safety that the contents have been written to disk, but does not do the bookkeeping required to use FILE_FLAG_NO_BUFFER. Fatal level events are automatically flushed/fsync-ed. Only a single writer to a file is allowed at any given time. This invariant exists because atomic flushes to files are only possible on Linux up to the page size used in the page cache. Only asynchronous IO is done, i.e. the Logary worker thread is not blocked by calls into the operating system. Because of the overhead of translating callbacks into Job/Alt structures, we try to write as much data as possible on every call into the operating system. This means that Messages to be logged can be ACKed in batches rather than individually. If your disk collapses while writing log messages (which happens once in a while and happens frequently when you have thousands of servers), the target should save its last will and then retry a configurable number of times after waiting an exponentially growing duration between each try. It does this by crashing and letting the supervisor handle the failure. After exhausting the tries, the batch of log messages is discarded. If there are IO errors on writing the log messages to disk, there ' s no guarantee that there won ' t be duplicate log lines written; however, they ' re normally timestamped, so downstream log ingestion systems can do de-duplication. This is from the batched nature of the File target. You write a Message from your call-site, this message is synchronised upon between the sending thread and the receiving thread using Hopac. If you use one of the logWithAck functions, placing the message in the RingBuffer can be awaited (or NACKed)  If you use the logSimple function, the synchronisation is hoisted onto the concurrency scheduler ' s pending queue and raced with a timeout to be discarded if the logging subsystem is overwhelmed. Once the Message is in the RingBuffer of the File target, it ' s either removed by itself, or as part of a batch, to be serialised to string. The serialisation function reads through the values of the message and uses the formatter function to write those values into a TextWriter. The TextWriter is normally a StreamWriter writing to a FileStream. This means no extra strings need be created through concatenation. Depending on the inProcBuffer configuration flag, the TextWriter either supports buffering, which buffers the string inside the CLR process, or writes directly to the underlying file handle, which transitions the data to the kernel ' s ioctl subsystem. By default we don ' t buffer here. Depending on the flushToDisk configuration flag, the FileStream is or is not called with Flush(true), which forces a disk synchronisation. By default we let the page cache buffer these writes, to trade safety against throughput. This is similar to how most other targets work. Depending on the writeThrough flag; Messages written with the File target is only ACKed when they are durably on disk. Defaults to true. Note that disposing Logary, e.g. during application exit flushes all buffers. I ' ve been considering supporting   NO_BUFFERING  but this would require callers to possibly wait for the 4096 bytes buffer to fill up before ACKing messages. However, for low-throughput logging, where each log line may be around, say, 240 bytes of text, having the NO_BUFFERING flag set may end up losing us more than it gains us. https://support.microsoft.com/en-us/kb/99794 https://stackoverflow.com/questions/317801/win32-write-to-file-without-buffering https://winntfs.com/2012/11/29/windows-write-caching-part-2-an-overview-for-application-developers/ https://msdn.microsoft.com/en-us/library/windows/desktop/cc644950(v=vs.85).aspx https://msdn.microsoft.com/en-us/library/windows/desktop/aa363772(v=vs.85).aspx https://stackoverflow.com/questions/8692635/how-do-disable-disk-cache-in-c-sharp-invoke-win32-createfile-api-with-file-flag https://stackoverflow.com/questions/122362/how-to-empty-flush-windows-read-disk-cache-in-c https://ayende.com/blog/174785/fast-transaction-log-windows These runs illustrate the above points in a more direct manner. In all of these cases we ' re writing 10K events to disk. inProcBuffer = false, flushToDisk = true, caller awaits all acks at the end This is the safest option and takes 1.3 seconds to log, format and write 10K messages. I 2016-11-08T11:04:00.6125063+00:00: Event 1 [Logary.Samples.main] number = >  1 ... [12:04:02 DBG] Flushing to disk. ... I 2016-11-08T11:04:02.0201345+00:00: Event 9402 [Logary.Samples.main] number = >  9402 [12:04:02 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9403 [Logary.Samples.main] number = >  9403 I 2016-11-08T11:04:02.0201345+00:00: Event 9404 [Logary.Samples.main] number = >  9404 ... I 2016-11-08T11:04:02.0891350+00:00: Event 10000 [Logary.Samples.main] number = >  10000 [12:04:02 DBG] Flushing to disk. ... The interleaved flushes shows the batching functionality of the File target in action. inProcBuffer = false, flushToDisk = true, caller awaits all ack after each This example represents the worst-case usage of the safest configuration. I 2016-11-08T11:14:42.9071732+00:00: Event 1 [Logary.Samples.main] number = >  1 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:14:42.9711735+00:00: Event 2 [Logary.Samples.main] number = >  2 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9403 [Logary.Samples.main] number = >  3 [12:14:42 DBG] Flushing to disk. I 2016-11-08T11:04:02.0201345+00:00: Event 9404 [Logary.Samples.main] number = >  4 [12:14:42 DBG] Flushing to disk. ... I 2016-11-08T11:15:04.7635448+00:00: Event 10000 [Logary.Samples.main] number = >  10000 [12:15:04 DBG] Flushing to disk. With this configuration, the File target would still batch other threads '  Messages but since this example has a single thread producer, there ' s only a single Message available for the target every loop. inProcBuffer = true, flushToDisk = false, writeThrough=false caller awaits all acks at the end This is the least safe and most speedy option. Useful when you ' re shipping logs away from the node and configure those shippers in a safer manner. In this case, .Net and the operating system and the device drivers decide when to flush. On exit/dispose of Logary, all targets are always flushed. [12:32:05 INF] Event 1 ... [12:32:06 INF] Event 10000 [12:32:48 DBG] Shutting down Logary. ... [12:32:48 DBG] Flushing to disk. In this example, the actual time taken is dominated by the time to generate the messages. Unit test rotation code Then enable rotation Harden against exceptions during writes – mock FileSystem Development has been sponsored by   Tradera.com.  Logary also includes a logging target for   Google Cloud Stackdriver.  The target can be configured like so: open  Logary.Targets.Stackdriver\n\n let  projectId =  \" your gcloud project id \" \n // either a custom name, or you can use one of the well-known stream names that you can retrieve from [the lists](https://cloud.google.com/logging/docs/view/logs_index) \n // this name doesn ' t have to be url-encoded as per the spec, the target will do that for you \n // the specified log should exist before use \n let  logname =  \" the stream you want to log to \" \n // create your monitored resource: \n let  resource = ComputeInstance( \" my zone \" ,  \" my instanceId \" )\n // or container: \n // let resource = Container( \" my cluster \" ,  \" my namespace \" ,  \" my instanceID \" ,  \" my pod \" ,  \" my name \" ,  \" my zone \" ) \n // or appengine: \n // let resource = AppEngine( \" my moduleId \" ,  \" my version \" ) \n\n let  conf = StackdriverConf.create(projectId, logname, resource) Then, within withTargets: Stackdriver.create conf  \" target-name \" batching flushing the underlying library doesn ' t provide a flush mechanism yet  https://www.jaegertracing.io/  https://www.jaegertracing.io/download/ add ambientSpanId middleware to the target, if you want to use ambient span jaegerTargetConf | >  TargetConf.middleware Middleware.ambientSpanId then create span for some tracing, log message as usual: use  rootSpan = logger.buildSpan () | >  Span.setMessage (eventX  \" root span \" ) | >  Span.start\n\n do!  eventX  \" before some action: {userId} \"   > >  setField  \" userId \"   123  | >  logger.infoWithBP\n\n // do some action : ... \n\n do!  eventX  \" after some action: {orderId} \"   > >  setField  \" orderId \"   321  | >  logger.infoWithBP\n\n let  conStr =  \" Host=;Database=;Username=;Password=; \" \n\n use  childSpan = Span.create logger | >  Span.setMessage (eventX  \" child span \"   > >  tag  \" DB Query \"   > >  tag  \" Postgresql \"   > >  setContext  \" conn str \"  conStr) | >  Span.start\n\n let  sql =  \" select count(*) from xxx \" \n do!  eventX  \" query : {sql} \"   > >  setField  \" sql \"  sql  > >  setTimestamp (Instant.FromUnixTimeSeconds  1 L) | >  logger.infoWithBP if not using ambient span, you can use Message.setSpanId for log message and Span.setParentSpanInfo for childSpan creation. do!  eventX  \" after some action: {orderId} \"   > >  setField  \" orderId \"   321   > >  setSpanId rootSpan.info.spanId | >  logger.infoWithBP\n\n // use explicitly setParentSpanInfo style, since we use hopac `do! timeOutMillis 100` before (the ambientSpanId middleware will not be guaranteed) \n let  childSpan = Span.create logger | >  Span.setMessage (eventX  \" child span \"   > >  tag  \" DB Query \"   > >  tag  \" Postgresql \"   > >  setContext  \" conn str \"  conStr) | >  Span.setParentSpanInfo rootSpan.info | >  Span.start LogaryFactory.New( \" demoService \" ,\n                    conf = >  conf\n                            .InternalLoggingLevel(LogLevel.Verbose)\n                            .Target < Debugger.Builder > ( \" internal.debugger \" , tb = >  tb.UseForInternalLog())\n                            .Target < Logary.Targets.Console.Builder > ( \" internal.console \" , tb = >  tb.UseForInternalLog())\n                            .Target < LiterateConsole.Builder > ( \" console1 \" )\n                            .Target < AliYun.Builder > ( \" AliYunLog \" , tb = >  {\n                                 tb.MinLevel(LogLevel.Verbose)\n                                 .Target\n                                 .ConfClient( \" key \" ,\n                                              \" keyid \" ,\n                                              \" endpoint \" )\n                                 .ConfLogLocation( \" project \" ,  \" logstore \" )\n                                 .SetConnectTimeOut( 1000 )\n                                 .SetReadWriteTimeOut( 5000 )\n                                 .Done();\n                            })\n                    ); Target for   Microsoft Azure AppInsights   logs the events as TRACE-messages (or Events/Metrics with a different MappingConfiguration). You need to set the API-key first. Then when you go to Azure Portal Application Insights and  Overview - >  Search   you should be able to find the targets from there. Metrics goes to   Metrics Explorer - >  Add Chart - >  Custom.    More info... Logary is a production-grade logging and metrics library. We ' ve also built targets that integrate with external paid services. These are listed here. Learn how people use your app with the world ' s most advanced mobile  &  web analytics. [Purchase today](mailto:henrik@haf.se?subject=Logary Mixpanel Target) Ship logs from your iOS, Android app Ship logs and handle user identification and unique-id tracking from web Use your own domain and server (over HTTPS) Logary listens on your server and forwards your events into Mixpanel Add granular server-side event filtering/enriching/correlation for better insights before shipping them onwards. Log web app usage even when Mixpanel is blocked client-side We like open source – so in the purchase the reference source is provided so that it can be debugged like the rest of Logary. Send an e-mail to purchase This assumes you have an account at  Mixpanel.   You can ' t rely on any one notification method for critical alerts. Get alert notifications via iOS  &  Android push, SMS, and phone calls; escalate automatically to team members if the alert is not acknowledged. The Logary target for OpsGenie ensures that you can bring in your Logging and Metrics into your daily operations. Connect using your own API key Make Logary events into new alerts Supports custom  ' enrichers '  to let you specify e.g. user, teams, recipients, tags, entity and notes, to name a few. Ready to use from both F# and C# Use derived metrics to create load-level alerts Stay on top of your infrastructure Avoid blacklisting your transactional e-mail service This assumes you have an account at   OpsGenie.  source https://www.nuget.org/api/v2   nuget Logary.Targets.Elmah.Io  OR:  Install-Package Logary.Targets.Elmah.Io  Configure elmah.io just like you would any normal target. # if  INTERACTIVE\n#I  \" bin/Release \" \n#r  \" Hopac.Core.dll \" \n#r  \" Hopac.dll \" \n#r  \" NodaTime.dll \" \n#r  \" Logary.dll \" \n#r  \" Logary.Riemann.dll \" \n#endif\n\n open  System\n open  NodaTime\n open  Hopac\n open  Logary\n open  Logary.Configuration\n open  Logary.EventProcessing\n open  Logary.Targets\n open  Logary.Targets.ElmahIO\n open  System.Threading\n\n [ < EntryPoint > ] \n let  main argv =\n   use  mre =  new  ManualResetEventSlim( false )\n   use  sub = Console.CancelKeyPress.Subscribe ( fun  _ - >  mre.Set())\n\n   let  logary =\n     let  elmahioConf =\n      { logId = Guid.Parse(Environment.GetEnvironmentVariable( \" ELMAH_IO_LOG_ID \" ))\n        apiKey =  \" api key form elmah io \" }\n\n    Config.create  \" Logary.ElmahIO \"   \" localhost \" \n    | >  Config.targets [\n        Console.create Console.empty  \" console \" \n        ElmahIO.create elmahioConf  \" elmah.io \" \n      ]\n    | >  Config.processing (Events.events | >  Events.sink [ \" console \" ; \" elmah.io \" ;])\n    | >  Config.build\n    | >  run\n\n   let  logger =\n    logary.getLogger (PointName [|  \" Logary \" ;  \" Samples \" ;  \" main \"  |])\n\n  Message.eventFormat( \" {userName} logged in \" , [|  \" haf \"  |])\n  | >  Logger.logSimple logger\n\n  Message.eventFormat (Info,  \" {userName} logged in \" , [|  \" adam \"  |])\n  | >  Logger.logSimple logger\n\n  mre.Wait()\n   0 Or from C#: // ... \n.Target < ElmahIO.Builder > (\n   \" elmah.io \" ,\n  conf = >  conf.Target.WithLogId( \" GUID_HERE \" )) You ' ll get the same view by logging this Message: type   Tenant   =\n  { tenantId : string\n    permissions : string }\n\n let  exnMsg =\n  Message.event Error  \" Unhandled exception \" \n  | >  Message.setSimpleName  \" A.B.C \" \n  | >  Message.setFieldFromObject  \" tenant \"  { tenantId =  \" 12345 \" ; permissions =  \" RWX \"  }\n  | >  Message.setContextFromMap (Map\n    [  \" user \" , box (Map\n        [  \" name \" , box  \" haf \" \n           \" id \" , box  \" deadbeef234567 \" \n        ])\n    ])\n  | >  withException Message.addExn This assumes you have an account at   elmah.io. SumoLogic is a hosted service (at about 99 USD per month) that unifies logging, metrics, analytics and dashboards in a single service. As such it ' s a perfect Target for Logary, since Logary supports both logs and metrics. Have a look at @neoeinstein ' s   Logary.Targets.SumoLogic   for the official docs and a sample of how to use it.  source https://www.nuget.org/api/v2   nuget Logary.Targets.SumoLogic  Absolutely! You have two options; Send a PR with your target that is of equivalent quality as the rest of the code-base, including documentation, code-doc, the C# builder API and a sample in this file. Then keep that code up-to-date when Logary evolves and your SaaS service changes its APIs. Send me an e-mail and I ' ll target the target for you. Pricing: a small initial fee and then a monthly maintenance fee, you ' ll have a beautiful way of getting logs and metrics to your servers!. This is by far the easiest option and ensures that your Target is stable and easy to use for your customers. I ' ll even write some Markdown/HTML-formatted docs for your site about how to use Logary with your target. InfluxDB File target Stackdriver target Jaeger tracing target AliYun Log Service target Azure AppInsights target Commercial targets Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/dotnet/targets\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/dotnet/targets"},"6":{"id":"6","title":"","subtitle":[],"description":"","body":"body{display:none} body{display:block} JavaScript docs Logary Analytics Start JavaScript docs Logary JS docs Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/js/docs\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/js/docs"},"7":{"id":"7","title":" — Logary","subtitle":["Install the package","How to use"],"description":"","body":"body{display:none} body{display:block} JavaScript Quickstart Logary Analytics Start JavaScript Quickstart   Reading time:  3  minutes The first step is to install the Logary package from npm. npm install --save logary Or you ' re using yarn... yarn add logary import  Logary, { build,  /* send */  getLogger, defaultTarget, Message }  from   ' logary ' \n // Supply this for your own user \n const  user = {  id :  ' abc ' ,  name :  ' A B ' ,  email :  ' a.b@example.com '  } \n\n // Where to send logs? \n const  target = defaultTarget;  // OR: \n\n // ALTERNATIVELY: You can have one of these globally per application. \n // const filter = next = >  req = >  next(req); // No infrastructure/non-functional requirements on requests \n\n // A CUSTOM TARGET (uncomment send, filter, above): \n // const target = Targets.logaryService({ \n //   path:  ' http://localhost:10001/i/logary ' , \n //   send: send(), // OR: \n //   send: filter(send()) \n // }) \n\n // This instance is configured for the example user: \n // You can have one of these prepared when the user logs in, in the user state store. \n const  logary = Logary(user, target,  \" MyWebApp \" );\n\n // With  ' build '  we get a  \" live \"  function that can send to a target/server, use it to log \n // You can have one of these in each of your module  \" screens \" /parents \n const  sendMessage = build(logary, getLogger(logary,  \" MyModule \" ))\n\n // Send a message! \n // You can have one of these whereever you need to track stuff! \nsendMessage(Message.event( \" App started \" )).subscribe() You can spawn Rutta server-side as a docker container, to ingest logs: $ docker run -p 10001:10001 --rm -it haaf/rutta router --listener http 0.0.0.0:10001 json --target console://./ You can choose between the different targets when forwarding the logs (see the main logary repo) Install the package How to use Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/js/quickstart\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/js/quickstart"},"8":{"id":"8","title":" — Logary","subtitle":["FAQ","How do I use Hopac from C#?","What","'","s logVerboseWithAck, logWithAck and how does it differ from logSimple?","Getting MissingMethodException from FSharp.Core","Is v5.0.x a stable version?","Why does Logary depend on FParsec?","Why do you depend on Hopac?","Getting MissingMethodException from Hopac.Core","Comparison to NLog and log4net","Comparison to NLog and log4net","Comparison to Codahale metrics ","&"," Metrics.NET","Logary and Serilog","Comparison with Serilog"],"description":"","body":"body{display:none} body{display:block} FAQs Logary Analytics Start FAQs   Reading time:  6  minutes You ' re better off following the examples in C# and using the Task-wrapped public APIs than going spelunking into the dire straits of Hopac and F#. Just pull in Logary.CSharp to make this happen. You ' ll also have to open the Logary namespace. To start with, if you ' re new to Logary, you can use logSimple and it will work like most other logging frameworks. So what are those semantics exactly? Logary runs its targets concurrently. When you log a Message, all targets whose Rules make it relevant for your Message, receives the Message, each target tries to send that Message to its, well, target. Because running out of memory generally is unwanted, each target has a   RingBuffer   that   the messages are put into   when you use the Logger. Unless all targets '  RingBuffer accept the Message, the call to log doesn ' t complete. This is similar to how other logging frameworks work. But then, what about the call to log? Behind the scenes it calls lockWithAck and tries to commit to the returned Alt [Promise [unit]] (the outer Alt, that is). If the RingBuffer is full then this Alt cannot be committed to, so there ' s code that drops the log message after 5000 ms. Hence; logSimple tries its best to log your message but if you app crashes directly after calling logSimple or your Logstash or other target infrastructure is down, you cannot be sure everything is logged. The decision was made that it ' s more important that your app keeps running than that all targets you have configured successfully log your Messages. The outer Alt ensures that the Message has been placed in all configured targets '  RingBuffers. The inner Promise that the Message has successfully been written from all Targets that received it. It ensures that your logging infrastructure has received the message. It ' s up to each target to deal with Acks in its own way, but a  ' best-practices '  Ack implementation can be seen in the RabbitMQ target. It ' s a best-practices Ack implementation because RabbitMQ supports publisher confirms (that serve as Acks), asynchronous publish and also durable messaging. The C# signature of the above functions is as follows: type Message =\n  [ < Extension > ]\n   static  member  LogWithAck  ( logger, message, bufferCt, promiseCt ) : Task < Task >  =\n    Alt. toTasks bufferCt  promiseCt  ( Logger.logWithAck logger message ) and can be used like so: var  message = MessageModule.Event(LogLevel.Warn,  \" Here be dragons! \" );\n // force the buffers of all configured targets to be flushed \n await  logger.LogWithAck(message); You need to add a rebind to the latest F# version in your executable: < ?xml version= \" 1.0 \"  encoding= \" utf-8 \" ? > \n < configuration > \n   < runtime > \n     < assemblyBinding   xmlns = \" urn:schemas-microsoft-com:asm.v1 \" > \n       < dependentAssembly > \n         < Paket > True < / Paket > \n         < assemblyIdentity   name = \" FSharp.Core \"   publicKeyToken = \" b03f5f7f11d50a3a \"   culture = \" neutral \"  / > \n         < bindingRedirect   oldVersion = \" 0.0.0.0-999.999.999.999 \"   newVersion = \" 4.4.0.0 \"  / > \n       < / dependentAssembly > \n     < / assemblyBinding > \n   < / runtime > \n < / configuration > Yes, it ' s very stable. For tow reasons; we use Chiron for json formatting which depend on FParsec Aether is vendored in Logary.Utils.Aether and depend on it. Hopac supports a few things that async doesn ' t: Rendezvous and selective concurrency primitives (select A or B) Negative ACKs instead of CancellationToken-s We also wanted support for synchronous rendezvous between channels/job/alts/promises/etc. This still supports asynchronous operations towards the outside. Together it makes for an excellent choice for cooperating  ' agents ' , like the Registry and Supervisor and Target Instance that we have in the library. Besides the technical upsides, it ' s a good thing there ' s a book written about the concurrency model that Hopac implements –   Concurrent Programming in ML   which lets us get developers up to speed quickly. Finally, our unit tests sped up 30x when porting from Async. The performance boost is a nice feature of a logging framework and comes primarily from less GC collection and the  ' hand off '  between synchronising concurrency primitives being synchronously scheduled inside Hopac rather than implemented using Thread/Semaphore/Monitor primitives on top of the ThreadPool. Inspect the version specified in the   Logary package   and ensure that you have that exact version installed. Hopac is currently pre-v1 so it is often doing breaking changes between versions. Why Logary instead of one of the classic logging frameworks? You get semantic logging with Logary More targets to choose from Larger community of target writers Easier to write targets; they can crash and that ' s handled by Logary internally Support for zero-dependency usage through Logary.Facade Better/more extensive Rule-based hierarchies Targets can be decoupled from the network and Ack is a first-level primitive You get back an   Alt (Promise (unit) )  that you can use to synchronise your calling code for when the log message is required to be durable; you can ' t do this with NLog or log4net There ' s an object model you can use from the calling code Logary is F#, so it ' s easier to keep bug-free relative to many other languages Logary doesn ' t keep static state around; easy to refactor, easy to extend Why Logary rather than Metrics.NET? In order to understand the differences, you first need to understand the vocabulary. Logary uses the name   Message   to mean either an  Event   , a   Gauge   or a   Derived  . This comes from analysing the different sorts of things one would like to ship from an app. Starting with an   Event  ; this is the main value when you ' re logging (in fact, it ' s Logary.PointValue.Event(template:string) that you ' re using.) An event is like a Gauge at a particular instant on the global timeline with a value of 1 (one). Which brings us to what a   Gauge   is. It ' s a specific value at an instant. It ' s what you see as a temporature on a thermometer in your apartment, e.g.   10.2 degrees celcius  . In the International System of Units (SI-Units), you could say it ' s the same as 283.2 K. Logary aims to be the foundational layer for all your metrics, so it uses these units. A   Gauge   value of your temperature could be created like so   Message.gaugeWithUnit Kelvin (Float 283.2)   or   Gauge (Float 283.2, Kelvin)  . A   Derived metric  , like   Kelvin/s   is useful if you ' re planning on writing a thermostat to control the temperature. A change in target temperature causes a rate of change. Another sample metric could be represented by the name   [|  \" MyApp \" ;  \" API \"   \" requests \"  |]   and   PointValue   of   Derived (Float 144.2, Div (Scalar, Seconds))  , if the API is experiencing a request rate of 144.2 requests per second. Armed with this knowledge, we can now do a mapping between Codahale ' s metrics and those of Logary:  Gauges   (measuring instantaneous values) - >    PointValue.Gauge(.., ..)  .  Timers   (measuring durations) - >    PointValue.Gauge(.., Scaled(Seconds, 10e9)   (in nanoseconds)  Meter   (measuring rates) - >    PointValue.Derived(.., Div(Scalar, Seconds))   or   PointValue.Derived(.., Div(Other  \" requests \" , Seconds))    Counters   (counting events) - >    PointValue.Event( \" User logged in \" )  Histograms   (tracking value distributions) - >    PointValue.Derived   (with suffixes) and   Reservoirs.  Metrics like the above are taken from different sources: At call site (e.g.  \"  Event   happened \" , or  \" it took   50 ns to connect  \" ) At a process level, derived from  Gauge   and   Event   from different call-sites in your app (e.g.  \" The 99.9th percentile of  ' [time] ns to connect '  is 145 ns \" ). At process level, taken from the operating system (Process is using 36.3% of CPU) At a system level (e.g. the CPU utilisation is 0.352% – which can be represented as let  mhz = Div(Scaled(Hz,  1e-6 ))  in  Gauge(Fraction ( 1300 ,  36800 ), Div(mhz, mhz)) as collected by Rutta ' s Shipper from a compute node. The aim of Logary is to connect values from call-sites, to configurable derivations, such as percentiles(, potentially again to derivations), and finally to targets which can then store them. Both support structured logging Both run on .Net Logary is based on cooperative multithreading whilst Serilog is mostly lock-free concurrent Logary was built from running high-throughput distributed systems 24/7 in production and has learnt its lessons similar to Serilog. Logary can be run in multi-instance mode without using any global shared state (aka. statics), which is similar to Serilog Serilog ' s Enrichers = Logary ' s middleware Serilog ' s Sink = Logary ' s Target Targets in Logary tend to use IO completion ports/async-as- \" green threads \" , AFAIK Sinks are running and calling out using synchronous/blocking APIs to a larger extent Logary supports flushing all targets ( LogManager.Flush ) Logary supports flushing a single target ( Target.flush ) Logary supports backpressure (F#:  Alt < _ >  , C#:  Task ) returned from logWithAck . Logary further supports backpressure by waiting for all targets to flush a particular message (e.g. you should always block on Fatal messages to finish logging) through  Alt < Promise < unit > > / Task < Task >  in C# (same method as above). Logary ' s C# API doesn ' t support misconfiguring Logary, because it ' s been built with chaining types together (going beyond the  return this  pattern) – similar to Serilog but with a more callback-oriented API. Logary supports Metrics – Gauges, Derived values, Histograms, Reservoirs Logary supports Health checks out of the box Logary has built-in support for Windows Performance Counters metrics shipping through  Logary.Metrics.WinPerfCounters . Logary provides a Facade for your libraries to depend on, to avoid dependency hell forcing you to upgrade all your libraries whenever Logary changes (which it does often, in order to improve!) – a single  Facade.[fs,cs] -file that you version control yourself. Logary supports Targets that batch, out of the box, similar to Serilog. The Target is responsible for choosing how many  Messages  it can send at once. Logary supports Targets that fail by restarting them Logary supports Targets '  last will – use to handle poison Messages Logary is written in F#, Serilog in C# Logary has a C# API  Logary.CSharp . Serilog doesn ' t have a F# API Logary supports adding structured data to metrics Logary ' s InfluxDb target supports fields and can batch multiple Windows Performance Counters or metrics into a single Measurement Logary has a JS-counterpart,  logary-js  which lets you log into Logary.Services.Rutta  on the server; events and metrics. Logary has paid support available if you need it. Logary supports the side-kick pattern, where you outsource your shipping of logs from your main process to a co-process through Rutta ' s Shipper and Router. Logary has  TimeScope  and the ability to instrument your code for sending timing information. Logary has preliminary support for Zipkin. Both are awesome and @nblumhardt is an awesome dude. Use whichever you feel most comfortable with! FAQ Comparison to NLog and log4net Comparison to Codahale metrics  &  Metrics.NET Logary and Serilog Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/faqs\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/other/faqs"},"9":{"id":"9","title":" — Logary","subtitle":["Logary licensing","Logary licencing","Logary Library (Logary-lib)","Logary Dash","Targets","Rutta","Library Façade"," JavaScript library","Terms of Service","Terms of Service (ToS)","1. Jurisdiction","2. Submission of Contributions","3. Limitation of Warranty","4. Limitation of Liability","5. Indemnification","6. Collection of statistics / environment data","7. Changes to the terms","Commercial license","Commercial License","1. Pricing","2. Allowances","3. Refunds","4. Order a license"],"description":"","body":"body{display:none} body{display:block} License Logary Analytics Start License   Reading time:  5  minutes This section defines the licenses for each subcomponent of Logary. Present at src/Logary[,Tests,PerfTests] and src/adapters/*. Each being a .Net library that you link your own code/software to. Non-profits and non-profit projects are free to use without payment, subject to the Terms of Service defined below. For-profit or commercial entities must purchase licenses to use Logary for their production environments, subject to the Terms of Service defined below. Present at src/services/Dash and src/targets/Logary.Targets.SSE; a web app and an EventSource/SSE based target. Non-profits and non-profit projects are free to use without payment, subject to the Terms of Service defined below. For-profit or commercial entities must purchase licenses to use Dash for their production environments, subject to the Terms of Service defined below. Present at src/targets/*, being .Net libraries that you link your own software to, or add as plugins to Rutta. Targets incorporated into the Logary code-base cannot be used without using the Logary library, but their code is free to modify, extend and sell under the Apache 2.0 license, unless specified otherwise on a per target basis (see below). The following targets '  licenses must always be purchased, independent of the for-profit status of the purchasing entity: Mixpanel (under   src/targets/Logary.Targets.Mixpanel  ) — commercial user analytics, segmentation Opsgenie (under   src/targets/Logary.Targets.Opsgenie)   — commercial alerting and monitoring All other targets (and their code-bases) are licensed as Apache 2.0 (Appendix A contains links to Apache 2.0). Present at src/services/*, being an executable program and docker container. Rutta is dual-licensed as GPL v3, or as a commercial license. Purchasing a commercial license for Rutta lets you use and extend its source code for your own commercial purposes and not open source that change. Present at src/services/*, being an executable program and docker container. GPL v3 means that when you want to extend Rutta for your own purposes, you must send a pull request with that change in order to make your improvement available for others to use. This is so that free software can continue to be free. If you don ' t want to send a pull request with your change, you must purchase the commercial license. Present at   src/Logary[,CSharp].Facade[,.Tests]  . Also called the Façade, in short. The Façade is Apache 2.0 licensed. The Library Façade is distinct from the Façade Adapter, since the Façade is Apache 2.0-licensed code, whilst the Façade Adapter (in   src/adapters/Logary.Adapters.Facade  ) doesn ' t work without Logary-lib.  logary  MIT-licensed, see  logary/logary-js/LICENSE.   This NPM package is published at  logary/logary-js/LICENSE.   This software ' s license shall be interpreted in accordance with the laws of Sweden. 2.1. When you (Contributor) submit a pull request or otherwise seek to include your code in the Logary project, you waive all your intellectual property rights, including your copyright and patent claims for the submission. You agree that the modification that you submit may be relicensed as Logary ' s authors see fit. 2.2. Unless otherwise stated by Logary ' s authors, your contribution will be licensed as per the component it is for. 3.1. Logary and all of its services, adapters, libraries and related software are provided ‘as is’ and ‘as available’ without warranty of any kind. Your use of the software is solely your responsibility. Logary ' s authors do not grant you any warranties, express or implied or otherwise, as to the accessibility, quality, fitness for any particular purpose, suitability or accuracy of the software, to the extent permitted by applicable law. 3.2. We advice you to ascertain the fitness and functionality of the software yourself by fully testing it for your purposes and reading its source code. 4.1. To the extent permitted by applicable law, Logary ' s authors are not liable for any direct nor indirect loss suffered by you, unless they has been found guilty of gross negligence. This limitation of liability includes, but is not limited to, loss of production or sales, loss of profit and cost of capital. Logary ' s author ' s liability under this section shall, in any event, be limited to an amount of half a price base amount according to the 1962:381 law about common insurance (Sv: Lagen om Allmänna försäkringar). You will indemnify and hold Logary ' s authors harmless from any claim or demand, including reasonable attorneys '  fees, made by any third party due to or arising out of your breach of these Terms, our policies, or your violation of any law or the rights of a third party, to the extent permitted by applicable law. You agree that Logary may collect statistics on its usage and runtime environment (operating system name and version, IP-address, the hostname that is running Logary components, linked library identifiers, etc), by means of communication with Logary authors '  servers. Logary ' s authors may make changes to these Terms from time to time. When we introduce changes we will commit the most current version to this document, and if a revision of the Terms is material and you have made a purchase of the commercial license, we will notify you of the new Terms (either by e-mail or a Github notification) as appropriate. If you do not agree to the modified terms, you should discontinue your use of Logary. This section defines the terms of the Commercial License. The Commercial License is subject to the Terms of Service (ToS) above. It applies to a Work or Software, its source code and the running/deployment of the software. The commercial license must be purchased in order to apply to the Software. The price in EUR (€) is calculated as follows: price = C * 100 + D * 20 + 250 where C: # of cores in total production deployment D: # of developers owning/working on the software You can load- and stress-test in a test-/staging-environment, for free, as long as that environment never serves production traffic. If you change the number of cores you deploy on, or number of developers, please order a delta to your license. You must renew the license(s) yearly, at a 60% discount of the initial price that a new customer would pay at the instant when the license expires. So for example, if you have 5 different services, each with access to 10 cores, and your team is 5 backend and 2 frontend developers, you pay 10 * 100 + 5 * 20 + 250 = €1,350 euro the first year, and €540 every subsequent year if the number of cores used in production and the number of developers  \" owning \" /building the software is the same. You may choose to pay via invoice (SWIFT/IBAN bank transfer, or via a lightning network invoice), or through credit/debit card. The invoice must be paid within 10 days of its issuance. Credit/Debit card payments are immediate. By purchasing this license you may make changes to the Software without open sourcing or sending a pull request with those changes. Furthermore, you are free to link the Software to your own software, under the terms of this license. Unless expressly agreed in writing, before the purchase, there are no refunds, to the extent of the applicable law. If you are purchasing an individual, you have 14 days right to withdrawal according to  Swedish law.   Send an e-mail to   henrik@haf.se   with the number of cores and developers you ' d like to purchase a license for. Logary licensing Terms of Service Commercial license Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/license\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/other/license"},"10":{"id":"10","title":" — Logary","subtitle":["Calculator","Calculator","Purchase license","Purchase license"],"description":"","body":"body{display:none} body{display:block} Pricing Logary Analytics Start Pricing   Reading time:  3  minutes Logary ' s pricing is transparent. You don ' t have to sign up to a newsletter to know what it would cost you to run it for your for-profit service. Licenses are yearly and subscription based. You can load- and stress-test in a test-/staging-environment, for free, as long as that environment never serves production traffic. Number of cores in total production deployment 1 core 8 cores 30 cores Number of developers owning/working on the software (seats) 1 developer 3 developers 15 developers Number of years to buy a license for 1 year 2 years 15 years Total (for  2  years):  1554 EUR Subsequently:  444 EUR /year Your license will be delivered by e-mail 📧 upon purchase. This form reflects your selection above. You ' re purchasing a license for  8  cores,  3  developers for  2  years. This sets up a subscription, so that after  2 years , you ' ll be charged  444 EUR  at the beginning of the year. Subtotal:  1554 EUR VAT (25%):  388.5 EUR Total:  1942.5 EUR Pay 1942.5 EUR Calculator Purchase license Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/pricing\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/other/pricing"},"11":{"id":"11","title":" — Logary","subtitle":["File guidelines – module vs static method","File guidelines – plural vs singular","Namespace guidelines","Namespace guidelines ","RuntimeInfo ","&"," internal logging","A new function?","Opening namespaces","Starting Hopac Jobs","Writing a new target"],"description":"","body":"body{display:none} body{display:block} Tutorials Logary Analytics Start Tutorials   Reading time:  12  minutes Clone it like above. Ensure you can build it. Open   Logary.sln  . Make a change, send a PR towards master. To balance the app.config files, try   mono tools/paket.exe install --redirects --clean-redirects --createnewbindingfiles Declare your interfaces in a   MyIf.fs   and its module in   MyIfModule.fs   with a ([CompilationRepresentation(CompilationRepresentationFlags.ModuleSuffix)])). Place these files as high as possible. Place the module as close to and below the non-module file as possible. If it ' s plausible that one would like to use point-free programming with your functions, place them in a module. (E.g. Message versus MessageModule) Factory methods go on the types for value types. For stateful objects they go on the module, named   create   which may or may not return a   Job[]   of some public state type with a private/internal constructor. (E.g. PointName versus Engine) All implementations go in a plural namespace. E.g.   Logary.Metrics.Ticked   has: Logary  – core namespace Metrics  – namespace for all metrics implementations Ticked  – a module and/or type that implements Logary-based ticking/ scheduling. Another example:   Logary.Target  , which is a module that implements logic about the life-cycle of target instances. It ' s used to start/stop/pause and shutdown targets. It ' s singular. –  Logary.Internals  or not Things that end-users of the library are not likely to configure should go in  Logary.Internals  . Examples include   Logary.Internals.Globals   and   Logary.Internals.RuntimeInfo   (which is configured with the config API instead). The   RuntimeInfo   and internal   Logger   should be propagated to the modules and objects that you build your solution out of. This guideline is mostly about the registry ' s implementation and its interaction with config and services. Generally, keep your functions to a single responsibility and compose functions instead of extending existing functions. Composition happens through currying and partial application of  ' state '  or  ' always-this-value '  values. For state it can both go through the Services abstraction (start/pause/stop/etc) or by closing over the state with a function. If you find that your functions are getting larger than 3 lines of code, you should probably extract part of the function. By  ' default '  it ' s better to be 1% less performant but 5% more readable, after this list of priorities: Correct CReadable/SRPorrect Fast/efficient/performant Prefer to open a namespace over fully qualifying a type. Prefer to open fully qualified over partial. open  Logary.Internals  open  Logary.Internals.Supervisor Instead of open  Logary.Internals  open  Supervisor A module function like   MyModule.create: Conf - >  Job[T]   should not start the server loop. Instead, just return a cold job (that can be started multiple time) and let the composition  \" root \" , such as the   Registry  , perform the composition and lifetime handling. Are you thinking of creating a new Target for Logary? It ' s a good idea if you can ' t find the right Target for your use case. It can also be useful if you have an internal metrics or log message engine in your company you wish to ship to. Create a new .net 4.5.1 class library in F#, under target and add that to Logary.sln. Copy the code from Logary ' s Targets/Noop.fs, which contains the basic structure. There are more docs in this file, to a file named MyTarget.fs in your new project. Add a nuget reference (or project reference if you ' re intending to send a PR) to Logary Write your Target and your Target ' s tests to ensure that it works Remember to test when the call to your server throws exceptions or fails You should use   Http.fs   as the HTTP client if it ' s a HTTP target When writing the Target, it ' s useful to keep these guidelines in mind. It should be able to handle shutdown messages from the shutdown channel It should not handle  ' unexpected '  exceptions, like network loss or a full disk by itself, but instead crash with an exception – the Logary supervisor will restart it after a short duration. Things that are part of the target API, like different response status codes of a REST API should be handled inside the Target. Don ' t do blocking calls; Convert  Task < _ >  and  Async < _ >  to  Job < _ >  by using the Hopac conversion methods If you need to block, use  Scheduler.isolate  so that your blocking call doesn ' t stop all Targets. Choose whether to create a target that can re-send crashing messages by choosing between  TargetUtils.[willAwareNamedTarget, stdNamedTarget] You can choose between consuming Messages one-by-one through RingBuffer.take  or in batches with  RingBuffer.takeBatch If you take a batch and the network call to send it off fails, consider sending the batch to the  willChannel  and throw an exception. Your target will be re-instantiated with the batch and you can now send the messages one-by-one to your target, throwing away poison messages (things that always crash). If your target throws an exception, the batch of Messages or the Message you ' ve taken from the  RingBuffer  will be gone, unless you send it to the will  channel. Exiting the loop will cause your Target to shut down. So don ' t catch all  exceptions without recursing afterwards. The supervisor does  not restart targets that exit on their own. If your target can understand a service name, then you should always add the service name from  RuntimeInfo.serviceName  as passed to your loop function. The  RuntimeInfo  contains a simple internal logger that you can assume always will accept your Messages. It allows you to debug and log exceptions from your target. By default it will write output to the STDOUT stream. If you don ' t implement the last-will functionality, a caller that awaits the Promise in  Alt < Promise < unit > >  as returned from  logWithAck , will block forever if your target ever crashes. If you need to do JSON serialisation, consider using  Logary.Utils.Chiron and  Logary.Utils.Aether , which are vendored copies of Chiron  and  Aether . Have a look at the Logstash Target  for an example. When your Target is finished, either ping  @haf  on github,  @henrikfeldt  on twitter, or send a PR to this README with your implementation documented. I can assist in proof-reading your code, to ensure that it follows the empirical lessons learnt operating huge systems with Logary. File guidelines – module vs static method File guidelines – plural vs singular Namespace guidelines RuntimeInfo  &  internal logging A new function? Opening namespaces Starting Hopac Jobs Writing a new target Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/other/tutorial\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/other/tutorial"},"12":{"id":"12","title":" — Logary","subtitle":["Usage","With Docker","In depth","The Shipper — from env to Proxy or Router","The Proxy — from Shipper to Router","The Router — from Shipper/Proxy to Target","Helm chart","Logary Rutta Helm chart","Install the chart","Router mode","Rutta Router mode"],"description":"","body":"body{display:none} body{display:block} Rutta – cloud native log router and event/log ingress Logary Analytics Start Rutta – cloud native log router and event/log ingress   Reading time:  12  minutes Route, forward and print logs anywhere to anything. docker run -p 10001:10001 --rm -it haaf/rutta router --listener tcp 0.0.0.0:10001 json --target console://./ Rutta is software for shipping Messages between computers. Either from your own services or from Windows Performance Counters. This is useful if you want your services to ship all logs to a central point, before batching it and sending it off to InfluxDb. It ' s also useful if you want to firewall off a single subnet for certain processing and only have a single point ship logs and metrics. v1: Hard-coded supported target types. Initially we ' ll just support InfluxDB. v2: More configurable target configuration that supports any target. This service can run in three modes; Shipper, Router and Proxy. Servers can be implemented using Hopac ' s lightweight servers. Communication is implemented using ZMQ and a binary serialisation format. Bindings look may look like this: Shipper - >  Router Shipper - >  Proxy Proxy - >  Proxy Proxy - >  Router   ZMQ socket reference On Windows you do   ./rutta.exe -- --pub-to ...   - note the two extra dashes before the parameter list. This is to avoid Topshelf munching the arguments away. Enables log shipping from hosts that are not directly connected to the router nor to InfluxDB.  Shippers CONNECT PUSH sockets to the Router ' s PULL socket. See   http://lists.zeromq.org/pipermail/zeromq-dev/2012-February/015917.html During network splits, the sending  PUSH socket blocks . During network splits, the sending XPUSH socket drops messages. Proxies take inputs from Shippers or other Proxies that publish Messages using XPUB sockets: The Proxy is run this way, by providing a XSUB socket binding and a XPUB socket binding: During network splits, the receiving   XSUB socket drops messages. You can then connect to the Proxy with a Router that routes it to the final Target (like InfluxDB in this example): During network splits, the sending   XPUB socket drops messages. Implements Fan-In using PULL or SUB of Messages from ZMQ. Forwards internally to a Target. V1 only implements the InfluxDB target. BINDs a PULL socket on a specified NIC/IP and PORT. Configures a single internal Target that pushes the received data. During network splits, the listening   PULL socket blocks.  BINDs a SUB socket on a specified NIC/IP and POST. Configures a single internal Target that pushes the received data. Serialisation for Rutta is done using  FsPickler . Since FsPickler uses a binary format, it should be assumed to break for any given minor upgrade of FsPickler. Each ZMQ message contains a Message (see DataModel.fs) in the binary form given by the serialiser chosen. The first step is to install the Rutta Helm chart into your Kubernetes cluster. Rutta is a high-performance log router/shipper written in F# but configured from the command line. It ' s  \" cloud native \"  in that it runs as a docker container on top of .Net Core Rutta is GPLv3 licensed (or alternatively commercially licensed). It ' s a packaging of Logary as a service, that you can run, either as a sidecar container or as a log router deployment. Rutta is completely stateless, so you can run any number of replicas. It runs as a Kubernetes deployment with three replicas by default. A common configuration for Rutta is to configure a Stackdriver target, a HTTP ingestion listener as well as a UDP ingestion listener. Your apps send UDP log messages to the UDP endpoint and your frontends (native apps and web sites) send HTTP messages to the HTTP endpoint. Rutta when batch-ships these log messages into Stackdriver. By default this chart exposes a HTTP listener/endpoint and prints to console; in order for it to log to Stackdriver, AliYun or AppInsights, you have to configure those explicitly in the values file. Have a look at the values.yaml file in order to get an idea of what you can configure. The first step is to install the Rutta Helm chart into your Kubernetes cluster. helm install https://github.com/logary/logary/tree/master/src/services/rutta-helm-chart  & &  \\\n    --name rutta  & &  \\\n    --namespace monitoring Or if you ' ve downloaded the chart; helm install ./rutta-helm-chart  & &  \\\n    --name rutta  & &  \\\n    --namespace monitoring If you use a local values file, you can upgrade the chart. helm upgrade --debug --install rutta  & &  \\\n    ./rutta-helm-chart  & &  \\\n    --namespace monitoring  & &  \\\n    --values values/rutta.yaml The router mode lets you take inputs from a `listener` (tcp, udp, ...), interpret it with a `codec` and then send it to a `target`. Usage With Docker In depth The Shipper — from env to Proxy or Router The Proxy — from Shipper to Router The Router — from Shipper/Proxy to Target Helm chart Router mode Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/rutta\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/rutta"},"13":{"id":"13","title":"","subtitle":[],"description":"","body":"body{display:none} body{display:block} tutorial-how Logary Analytics Start tutorial-how How Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/tutorials/how\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/tutorials/how"},"14":{"id":"14","title":"","subtitle":[],"description":"","body":"body{display:none} body{display:block} tutorial-visualise Logary Analytics Start tutorial-visualise How Designed by  Xiaoying Riley  for developers {\"props\":{\"pageProps\":{}},\"page\":\"/tutorials/visualise\",\"query\":{},\"buildId\":\"development\",\"nextExport\":true,\"autoExport\":true,\"isFallback\":false}","href":"/tutorials/visualise"}}